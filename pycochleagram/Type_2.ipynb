{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations file\n",
    "annotations = pd.read_csv('output.csv')\n",
    "data_dir = \"./applications/data/TUT-sound-events-2017-development\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define audio settings\n",
    "sr = 44100\n",
    "duration = 1.0\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "all_keys=['people walking', 'car', 'large vehicle', 'brakes squeaking', 'people speaking', 'children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namit\\miniconda3\\envs\\tf2-dcase\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=0\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels from audio segments\n",
    "features = []\n",
    "labels = []\n",
    "max_segments = 0\n",
    "audio_files = annotations['filename'].unique()\n",
    "for audio_file in audio_files:\n",
    "    file_path = os.path.join(data_dir, audio_file)\n",
    "    audio, _ = librosa.load(file_path, sr=sr)\n",
    "    segments = annotations[annotations['filename'] == audio_file]\n",
    "    for i, row in segments.iterrows():\n",
    "        event_time = row['events'].split(',')\n",
    "        start = int(float(event_time[0]) * sr/1000)\n",
    "        end = int(float(event_time[1]) * sr/1000)\n",
    "        segment = audio[start:end]\n",
    "\n",
    "        #mel_spec = librosa.feature.melspectrogram(segment, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "        #log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        oenv = librosa.onset.onset_strength(y=segment, sr=sr, hop_length=hop_length)\n",
    "        tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sr,\n",
    "                                      hop_length=hop_length)\n",
    "        features.append(tempogram)\n",
    "\n",
    "        label = np.zeros(6)\n",
    "        label[all_keys.index(row['event_type'])] = 1\n",
    "        labels.append(label)\n",
    "    num_segments = segments.shape[0]\n",
    "    if num_segments > max_segments:\n",
    "        max_segments = num_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad or truncate each sequence of features to match maximum number of segments\n",
    "padded_features = []\n",
    "for feat_seq in features:\n",
    "    num_pad_segments = max_segments - feat_seq.shape[1]\n",
    "    if num_pad_segments > 0:\n",
    "        padded_feat_seq = np.pad(feat_seq, ((0, 0), (0, num_pad_segments)))\n",
    "    else:\n",
    "        padded_feat_seq = feat_seq[:, :max_segments]\n",
    "    padded_features.append(padded_feat_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of features to a 3D array\n",
    "X = np.stack(padded_features, axis=0)\n",
    "X = tf.expand_dims(X, axis=-1)\n",
    "Y = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define event detection model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(n_mels, max_segments, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Reshape((-1, n_mels)),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.8 * X.shape[0])\n",
    "train_features = X[:train_size]\n",
    "train_labels = Y[:train_size]\n",
    "val_features = X[train_size:]\n",
    "val_labels = Y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 56, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 56, 1), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, 384, 56, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 56, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 56, 1), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, 384, 56, 1).\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.6758 - accuracy: 0.3833WARNING:tensorflow:Model was constructed with shape (None, 128, 56, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 56, 1), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, 384, 56, 1).\n",
      "17/17 [==============================] - 13s 667ms/step - loss: 1.6758 - accuracy: 0.3833 - val_loss: 1.3901 - val_accuracy: 0.6515\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 11s 634ms/step - loss: 1.5924 - accuracy: 0.4137 - val_loss: 1.2972 - val_accuracy: 0.6515\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 11s 624ms/step - loss: 1.5813 - accuracy: 0.4137 - val_loss: 1.2728 - val_accuracy: 0.6515\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 11s 637ms/step - loss: 1.5852 - accuracy: 0.4137 - val_loss: 1.4158 - val_accuracy: 0.6515\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 11s 676ms/step - loss: 1.5934 - accuracy: 0.4137 - val_loss: 1.2868 - val_accuracy: 0.6515\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 11s 655ms/step - loss: 1.5793 - accuracy: 0.4137 - val_loss: 1.3043 - val_accuracy: 0.6515\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 11s 635ms/step - loss: 1.5796 - accuracy: 0.4137 - val_loss: 1.2942 - val_accuracy: 0.6439\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 11s 656ms/step - loss: 1.5766 - accuracy: 0.4137 - val_loss: 1.3834 - val_accuracy: 0.6439\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 11s 645ms/step - loss: 1.5762 - accuracy: 0.4137 - val_loss: 1.2711 - val_accuracy: 0.6439\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 11s 666ms/step - loss: 1.5750 - accuracy: 0.4137 - val_loss: 1.3334 - val_accuracy: 0.6439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25436e05e10>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(train_features, train_labels, validation_data=(val_features, val_labels), batch_size=32, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 146ms/step - loss: 1.3334 - accuracy: 0.6439\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 56, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 56, 1), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, 384, 56, 1).\n",
      "Validation set loss: 1.3334\n",
      "Validation set accuracy: 0.6439\n",
      "Validation set F1 score: 0.1567\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on validation set\n",
    "loss, accuracy = model.evaluate(val_features, val_labels)\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred = model.predict(val_features)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(val_labels, axis=1)\n",
    "\n",
    "# Compute F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"Validation set loss: {:.4f}\".format(loss))\n",
    "print(\"Validation set accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Validation set F1 score: {:.4f}\".format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-dcase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
